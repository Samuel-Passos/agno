"""
Agente de Auto-Aprendizado
==========================
Aprendizado Cont√≠nuo GPU Poor: Aprendizado em n√≠vel de sistema sem fine-tuning.

O loop:
1. Buscar base de conhecimento por aprendizados relevantes
2. Coletar informa√ß√µes novas (busca, APIs)
3. Sintetizar resposta usando ambos
4. Identificar insight reutiliz√°vel
5. Salvar com aprova√ß√£o do usu√°rio

Constru√≠do com Agno + Gemini 3 Flash
"""

import json
from datetime import datetime, timezone

from agno.agent import Agent
from agno.knowledge.embedder.google import GeminiEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.text_reader import TextReader
from agno.models.google import Gemini
from agno.tools.parallel import ParallelTools
from agno.tools.yfinance import YFinanceTools
from agno.utils.log import logger
from agno.vectordb.pgvector import PgVector, SearchType
from db import db_url, gemini_agents_db

# ============================================================================
# Base de Conhecimento: armazena aprendizados bem-sucedidos
# ============================================================================
agent_knowledge = Knowledge(
    name="Agent Learnings",
    vector_db=PgVector(
        db_url=db_url,
        table_name="agent_learnings",
        search_type=SearchType.hybrid,
        embedder=GeminiEmbedder(id="gemini-embedding-001"),
    ),
    max_results=5,
    contents_db=gemini_agents_db,
)


# ============================================================================
# Ferramenta: Salvar Aprendizado
# ============================================================================
def save_learning(
    title: str,
    context: str,
    learning: str,
    confidence: str = "medium",
    type: str = "rule",
) -> str:
    """
    Salvar um aprendizado reutiliz√°vel de uma execu√ß√£o bem-sucedida.

    Args:
        title: T√≠tulo descritivo curto (ex: "Tratamento de limite de taxa de API")
        context: Quando/por que este aprendizado se aplica (ex: "Ao chamar APIs externas...")
        learning: O insight reutiliz√°vel real (seja espec√≠fico e acion√°vel)
        confidence: low | medium | high
        type: rule | heuristic | source | process | constraint

    Returns:
        Mensagem de status indicando o que aconteceu
    """
    # Validar entradas
    if not title or not title.strip():
        return "N√£o √© poss√≠vel salvar: t√≠tulo √© obrigat√≥rio"
    if not learning or not learning.strip():
        return "N√£o √© poss√≠vel salvar: conte√∫do do aprendizado √© obrigat√≥rio"
    if len(learning.strip()) < 20:
        return "N√£o √© poss√≠vel salvar: aprendizado √© muito curto para ser √∫til. Seja mais espec√≠fico."
    if confidence not in ("low", "medium", "high"):
        return f"N√£o √© poss√≠vel salvar: confian√ßa deve ser low|medium|high, recebido '{confidence}'"
    if type not in ("rule", "heuristic", "source", "process", "constraint"):
        return f"N√£o √© poss√≠vel salvar: tipo deve ser rule|heuristic|source|process|constraint, recebido '{type}'"

    # Construir o payload do aprendizado
    payload = {
        "title": title.strip(),
        "context": context.strip() if context else "",
        "learning": learning.strip(),
        "confidence": confidence,
        "type": type,
        "created_at": datetime.now(timezone.utc).isoformat().replace("+00:00", "Z"),
    }

    # Salvar na base de conhecimento
    try:
        agent_knowledge.add_content(
            name=payload["title"],
            text_content=json.dumps(payload, ensure_ascii=False),
            reader=TextReader(),
            skip_if_exists=True,
        )
    except Exception as e:
        logger.error(f"[Learning] Falha ao salvar: {e}")
        return f"Falha ao salvar aprendizado: {e}"

    logger.info(f"[Learning] Salvo: {payload['title']}")
    return f"Aprendizado salvo: '{payload['title']}'"


# ============================================================================
# Instru√ß√µes
# ============================================================================
instructions = """\
Voc√™ √© um Agente de Auto-Aprendizado que melhora com o tempo capturando e reutilizando padr√µes bem-sucedidos.

Voc√™ constr√≥i mem√≥ria institucional: insights bem-sucedidos s√£o salvos em uma base de conhecimento e recuperados em execu√ß√µes futuras. O modelo permanece fixo, mas o sistema fica mais inteligente.

## Ferramentas

| Ferramenta | Usar Para |
|------------|-----------|
| search_knowledge | Recuperar aprendizados anteriores relevantes |
| parallel_search | Busca web, informa√ß√µes atuais |
| yfinance | Dados de mercado, financeiros, informa√ß√µes de empresas |
| save_learning | Armazenar um insight reutiliz√°vel (requer aprova√ß√£o do usu√°rio) |

## Fluxo de Trabalho

Para cada solicita√ß√£o:

1. BUSCAR CONHECIMENTO PRIMEIRO ‚Äî Sempre chamar `search_knowledge` antes de qualquer coisa. Extrair conceitos-chave da consulta do usu√°rio e buscar aprendizados relevantes. Se nada relevante for encontrado, prosseguir sem contexto anterior.
2. PESQUISAR ‚Äî Usar `parallel_search` ou `yfinance` para coletar informa√ß√µes novas conforme necess√°rio.
3. SINTETIZAR ‚Äî Combinar aprendizados anteriores (se houver) com novas informa√ß√µes. Ao aplicar um aprendizado anterior, referenci√°-lo naturalmente: "Com base em um padr√£o anterior..." ou "Um aprendizado anterior sugere..."
4. REFLETIR ‚Äî Ap√≥s responder, considerar: esta tarefa revelou um insight reutiliz√°vel? A maioria das consultas n√£o produzir√° um aprendizado. Apenas sinalizar descobertas genu√≠nas.
5. PROPOR (se aplic√°vel) ‚Äî Se voc√™ identificou algo que vale a pena salvar, propor no final de sua resposta. Nunca chamar save_learning sem aprova√ß√£o expl√≠cita do usu√°rio.

## O Que Faz um Bom Aprendizado

Um aprendizado vale a pena salvar se for:
- Espec√≠fico: "Ao comparar ETFs, verificar taxa de despesa E erro de rastreamento" n√£o "Olhar m√©tricas de ETF"
- Acion√°vel: Pode ser aplicado diretamente em consultas futuras semelhantes
- Generaliz√°vel: √ötil al√©m desta quest√£o espec√≠fica

N√£o salvar: fatos brutos, respostas pontuais, resumos, especula√ß√£o ou qualquer coisa improv√°vel de recorrer.

A maioria das tarefas n√£o produzir√° um aprendizado. Isso √© esperado.

## Propondo um Aprendizado

Quando voc√™ tiver um insight genu√≠no que vale a pena salvar, terminar sua resposta com:

---
Aprendizado Proposto

T√≠tulo: [t√≠tulo conciso]
Tipo: rule | heuristic | source | process | constraint
Contexto: [quando aplicar isso]
Aprendizado: [o insight ‚Äî espec√≠fico e acion√°vel]

Salvar isso? (sim/n√£o)
---

Se o usu√°rio recusar, reconhecer e seguir em frente. N√£o repropor o mesmo aprendizado.
"""


# ============================================================================
# Create the Agent
# ============================================================================
self_learning_agent = Agent(
    name="Self-Learning Agent",
    model=Gemini(id="gemini-3-flash-preview"),
    instructions=instructions,
    db=gemini_agents_db,
    knowledge=agent_knowledge,
    tools=[
        ParallelTools(),
        YFinanceTools(),
        save_learning,
    ],
    # Habilitar o agente para lembrar informa√ß√µes e prefer√™ncias do usu√°rio
    enable_agentic_memory=True,
    # Habilitar o agente para buscar a base de conhecimento (ex: snapshots de pesquisa anteriores)
    search_knowledge=True,
    # Adicionar a data e hora atuais ao contexto
    add_datetime_to_context=True,
    # Adicionar o hist√≥rico das execu√ß√µes do agente ao contexto
    add_history_to_context=True,
    # N√∫mero de execu√ß√µes hist√≥ricas para incluir no contexto
    num_history_runs=5,
    # Dar ao agente uma ferramenta para ler hist√≥rico de chat al√©m das √∫ltimas 5 mensagens
    read_chat_history=True,
    markdown=True,
)


# ============================================================================
# CLI
# ============================================================================
if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
        self_learning_agent.print_response(query, stream=True)
    else:
        print("=" * 60)
        print("üß† Agente de Auto-Aprendizado")
        print("   Aprendizado Cont√≠nuo GPU Poor com Gemini 3 Flash")
        print("=" * 60)
        print("\nDigite 'quit' para sair.\n")

        while True:
            try:
                user_input = input("Voc√™: ").strip()
                if user_input.lower() in ("quit", "exit", "q"):
                    print("\nüëã At√© logo!")
                    break
                if not user_input:
                    continue

                print()
                self_learning_agent.print_response(user_input, stream=True)
                print()

            except KeyboardInterrupt:
                print("\n\nüëã At√© logo!")
                break
